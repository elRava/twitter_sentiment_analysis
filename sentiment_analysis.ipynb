{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data given is in the form of a comma-separated values files with tweets and their corresponding sentiments. The training dataset is a csv file of type tweet_id,sentiment,tweet where the\n",
    "tweet_id is a unique integer identifying the tweet, sentiment is either 1 (positive) or 0 (negative), and tweet is the tweet enclosed in \"\". Similarly, the test dataset is a csv file of type\n",
    "tweet_id,tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import nltk\n",
    "sys.path.insert(0, 'src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>is so sad for my APL frie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>I missed the New Moon trail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>omg its already 7:30 :O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>i think mi bf is cheating on me!!!   ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ItemID  Sentiment                                      SentimentText\n",
       "0       1          0                       is so sad for my APL frie...\n",
       "1       2          0                     I missed the New Moon trail...\n",
       "2       3          1                            omg its already 7:30 :O\n",
       "3       4          0            .. Omgaga. Im sooo  im gunna CRy. I'...\n",
       "4       5          0           i think mi bf is cheating on me!!!   ..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('dataset/train.csv', encoding = \"ISO-8859-1\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def handle_emojis(tweet):\n",
    "    # Smile -- :), : ), :-), (:, ( :, (-:, :')\n",
    "    tweet = re.sub(r'(:\\s?\\)|:-\\)|\\(\\s?:|\\(-:|:\\'\\))', ' EMO_POS ', tweet)\n",
    "    # Laugh -- :D, : D, :-D, xD, x-D, XD, X-D\n",
    "    tweet = re.sub(r'(:\\s?D|:-D|x-?D|X-?D)', ' EMO_POS ', tweet)\n",
    "    # Love -- <3, :*\n",
    "    tweet = re.sub(r'(<3|:\\*)', ' EMO_POS ', tweet)\n",
    "    # Wink -- ;-), ;), ;-D, ;D, (;,  (-;\n",
    "    tweet = re.sub(r'(;-?\\)|;-?D|\\(-?;)', ' EMO_POS ', tweet)\n",
    "    # Sad -- :-(, : (, :(, ):, )-:\n",
    "    tweet = re.sub(r'(:\\s?\\(|:-\\(|\\)\\s?:|\\)-:)', ' EMO_NEG ', tweet)\n",
    "    # Cry -- :,(, :'(, :\"(\n",
    "    tweet = re.sub(r'(:,\\(|:\\'\\(|:\"\\()', ' EMO_NEG ', tweet)\n",
    "    return tweet\n",
    "\n",
    "def preprocess_word(word):\n",
    "    # remove punctation\n",
    "    word = word.strip('\\'\"?!,.():;')\n",
    "    # more than 3 letter repetition removed\n",
    "    word = re.sub(r'(.)\\1\\1+', r'\\1\\1\\1', word)\n",
    "    # remove - & '\n",
    "    word = word.strip('-&\\'')\n",
    "    return word\n",
    "\n",
    "def is_valid_word(word):\n",
    "    # Check if word begins with an alphabet\n",
    "    return (re.search(r'^[a-zA-Z][a-z0-9A-Z\\._]*$', word) is not None)\n",
    "\n",
    "def preprocess_tweet(tweet, use_stemmer=False, use_lemmatizer=False):\n",
    "    # convert tweet to lowercase\n",
    "    tweet = tweet.lower()\n",
    "    # replace urls with 'URL'\n",
    "    tweet = re.sub(r'((www.[\\S]+)|(https?://.[\\S]+))', 'URL', tweet)\n",
    "    # replace user mentions @user with 'USER_MENTION'\n",
    "    tweet = re.sub(r'@[\\S]+', 'USER_MENTION', tweet)\n",
    "    # replace #hashtag with hastag\n",
    "    tweet = re.sub(r'#(\\S+)', r' \\1', tweet)\n",
    "    # remove retweet RT\n",
    "    tweet = re.sub(r'\\brt\\b', '', tweet)\n",
    "    # replace 2+ dots with space\n",
    "    tweet = re.sub(r'\\.{2,}', ' ', tweet)\n",
    "    # remove space, \" and ' \n",
    "    tweet.strip('\" \\'')\n",
    "    # handle emojis. Use only EMO_POS and EMO_NEG\n",
    "    tweet = handle_emojis(tweet)\n",
    "    # replace multiple spaces with only one space\n",
    "    tweet = re.sub(r'\\s+', ' ', tweet)\n",
    "    # preprocess words\n",
    "    words = tweet.split()\n",
    "\n",
    "    processed_words = []\n",
    "    porter_stemmer = PorterStemmer()\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    for word in words:\n",
    "        word = preprocess_word(word)\n",
    "        if is_valid_word(word):\n",
    "            if use_stemmer:\n",
    "                # use stemmer\n",
    "                word = str(porter_stemmer.stem(word))\n",
    "            elif use_lemmatizer:\n",
    "                word = str(wordnet_lemmatizer.lemmatize(word))\n",
    "            processed_words.append(word)\n",
    "    return ' '.join(processed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL:                      is so sad for my APL friend.............\n",
      "STEMMER: is so sad for my apl friend\n",
      "LEMMATIZER: is so sad for my apl friend\n",
      "----------------------------------------------------------------\n",
      "ORIGINAL:                    I missed the New Moon trailer...\n",
      "STEMMER: i miss the new moon trailer\n",
      "LEMMATIZER: i missed the new moon trailer\n",
      "----------------------------------------------------------------\n",
      "ORIGINAL:               omg its already 7:30 :O\n",
      "STEMMER: omg it alreadi o\n",
      "LEMMATIZER: omg it already o\n",
      "----------------------------------------------------------------\n",
      "ORIGINAL:           .. Omgaga. Im sooo  im gunna CRy. I've been at this dentist since 11.. I was suposed 2 just get a crown put on (30mins)...\n",
      "STEMMER: omgaga im sooo im gunna cri been at thi dentist sinc i wa supos just get a crown put on\n",
      "LEMMATIZER: omgaga im sooo im gunna cry been at this dentist since i wa suposed just get a crown put on\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#tweet = \"Hi, how is going on? :) CIAO COME vaaaaa? :) :( https://tartarus.org/martin/PorterStemmer/  bella @ivocerti    #sentimentanalysis\"\n",
    "for i in range(4):\n",
    "    tweet = dataset.loc[i]['SentimentText']\n",
    "    print('ORIGINAL: ' + tweet)\n",
    "    print('STEMMER: ' + preprocess_tweet(tweet, use_stemmer=True))\n",
    "    print('LEMMATIZER: ' + preprocess_tweet(tweet, use_lemmatizer=True))\n",
    "    print('----------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preprocessed_train_file = open('dataset/preprocessed_train.csv', 'w')\n",
    "preprocessed_train_file.write('ItemID,Sentiment,SentimentText\\n')\n",
    "for index, row in dataset.iterrows():\n",
    "    preprocessed_train_file.write(str(index+1) + ',' + str(row['Sentiment']) + ',' + preprocess_tweet(row['SentimentText']) + '\\n')\n",
    "    sys.stdout.write('\\r')\n",
    "    sys.stdout.write('Processing ' + str(index+1) + '/' + str(dataset.shape[0]))\n",
    "    sys.stdout.flush()\n",
    "preprocessed_train_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>is so sad for my apl friend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>i missed the new moon trailer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>omg its already o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>omgaga im sooo im gunna cry been at this denti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>i think mi bf is cheating on me t_t</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ItemID  Sentiment                                      SentimentText\n",
       "0       1          0                        is so sad for my apl friend\n",
       "1       2          0                      i missed the new moon trailer\n",
       "2       3          1                                  omg its already o\n",
       "3       4          0  omgaga im sooo im gunna cry been at this denti...\n",
       "4       5          0                i think mi bf is cheating on me t_t"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_dataset = pd.read_csv('dataset/preprocessed_train.csv', encoding = \"ISO-8859-1\")\n",
    "preprocessed_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature parameters (Word, SentiWordNet, POS + POS_Word, Semantic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import sentiwordnet as swn\n",
    "\n",
    "def word_to_SWNt(word):\n",
    "    # take the first result from sentiwordnet (if there is)\n",
    "    list_sent = list(swn.senti_synsets(word))\n",
    "    if len(list_sent) > 0:\n",
    "        sent = list_sent[0]\n",
    "        pos = round(sent.pos_score()*10)\n",
    "        neg = round(sent.neg_score()*10)\n",
    "        obj = round(sent.obj_score()*10)\n",
    "        # return the word if the word itself is mostly object\n",
    "        # otherwise return POS-X or NEG-X if the word is \n",
    "        # mostly positive or negative and X is the rounded score*10 (from 0 to 10)\n",
    "        if pos > neg:\n",
    "            return 'POS-' + str(pos)\n",
    "        elif neg > pos:\n",
    "            return 'NEG-' + str(neg)\n",
    "    return word\n",
    "\n",
    "def tweet_to_feature_word(tweet):\n",
    "    # just return the tweet as it is\n",
    "    return tweet\n",
    "\n",
    "def tweet_to_feature_SWNt(tweet):\n",
    "    words = tweet.split()\n",
    "    processed_words = []\n",
    "    for word in words:\n",
    "        processed_words.append(word_to_SWNt(word))\n",
    "    return ' '.join(processed_words)\n",
    "\n",
    "def tweet_to_feature_POS(tweet):\n",
    "    # the tweet is composed by the POS (parts of speech) of the words\n",
    "    # first just the list of pos, then the list of the pos and the words\n",
    "    # in the format pos_word\n",
    "    words = tweet.split()\n",
    "    words_POS = nltk.pos_tag(words)\n",
    "    processed_words = []\n",
    "    pos = []\n",
    "    for word in words_POS:\n",
    "        pos.append(word[1])\n",
    "    processed_words = pos\n",
    "    size = len(processed_words)\n",
    "    for i in range(size):\n",
    "        processed_words.append(processed_words[i] + '_' + words[i])\n",
    "    return ' '.join(processed_words)\n",
    "\n",
    "def tweet_to_feature_semantic(tweet):\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORD: is so sad for my apl friend\n",
      "SWNt: POS-2 so NEG-8 for my apl POS-1\n",
      "POS: VBZ RB JJ IN PRP$ NN NN VBZ_is RB_so JJ_sad IN_for PRP$_my NN_apl NN_friend\n",
      "----------------------------------------------------------------\n",
      "WORD: i missed the new moon trailer\n",
      "SWNt: i NEG-2 the POS-4 moon trailer\n",
      "POS: NN VBD DT JJ NN NN NN_i VBD_missed DT_the JJ_new NN_moon NN_trailer\n",
      "----------------------------------------------------------------\n",
      "WORD: omg its already o\n",
      "SWNt: omg its POS-1 o\n",
      "POS: VB PRP$ RB VB VB_omg PRP$_its RB_already VB_o\n",
      "----------------------------------------------------------------\n",
      "WORD: omgaga im sooo im gunna cry been at this dentist since i was suposed just get a crown put on\n",
      "SWNt: omgaga im sooo im gunna cry POS-2 at this dentist since i was suposed POS-6 get a crown put on\n",
      "POS: JJ NN NN NN NN NN VBN IN DT NN IN NN VBD VBN RB VB DT NN NN IN JJ_omgaga NN_im NN_sooo NN_im NN_gunna NN_cry VBN_been IN_at DT_this NN_dentist IN_since NN_i VBD_was VBN_suposed RB_just VB_get DT_a NN_crown NN_put IN_on\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    tweet = preprocessed_dataset.loc[i]['SentimentText']\n",
    "    print('WORD: ' + tweet_to_feature_word(tweet))\n",
    "    print('SWNt: ' + tweet_to_feature_SWNt(tweet))\n",
    "    print('POS: ' + tweet_to_feature_POS(tweet))\n",
    "    #print('Semantic: ' + tweet_to_feature_semantic(tweet))\n",
    "    print('----------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'missed', 'the', 'new', 'moon', 'trailer']\n",
      "NN\n",
      "NN\n",
      "VBD\n",
      "DT\n",
      "JJ\n",
      "NN\n",
      "NN\n"
     ]
    }
   ],
   "source": [
    "sentence = preprocessed_dataset.loc[1]['SentimentText']\n",
    "tokens = sentence.split()\n",
    "print(tokens)\n",
    "print(nltk.pos_tag(tokens)[0][1])\n",
    "a = nltk.pos_tag(tokens)\n",
    "for w in a:\n",
    "    print(w[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
